{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "from keras import activations\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.16, -21.640000000000015)\n",
      "102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:459: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sigma_noise = [2, 2]\n",
    "image_size = (200, 200)\n",
    "\n",
    "def generate_line(image):\n",
    "    a = int(random.uniform(-10, 10) * 100) / 100\n",
    "    p = (np.random.randint(image[0]), np.random.randint(image[1]))\n",
    "    b = p[1] - a*p[0]\n",
    "    return (a, b)\n",
    "\n",
    "def compute_line_from_points(p1, p2):\n",
    "    x1, y1 = p1\n",
    "    x2, y2 = p2\n",
    "    if (x2-x1) != 0:\n",
    "        a = int((y2-y1)/(x2-x1) * 100) / 100\n",
    "    else:\n",
    "        a = 100\n",
    "    b = y1 - a*x1\n",
    "    return (a, b)\n",
    "    \n",
    "\n",
    "def generate_data(line, image, sigma, n_inliers=100, n_outliers=10):\n",
    "    a, b = line\n",
    "    L_X = []\n",
    "    L_Y = []\n",
    "    Points = []\n",
    "    for x in range(image[0]):\n",
    "        y = a*x+b\n",
    "        if y >= 0 and y < image[1]:\n",
    "            p = np.array([x, y])\n",
    "            Points.append(p)\n",
    "    covariance = np.diag(np.array(sigma) ** 2)\n",
    "    n_i = max(1, n_inliers // len(Points))\n",
    "    for point in Points:\n",
    "        sample = np.random.multivariate_normal(point, covariance, n_i)\n",
    "        sample_X = map(int, sample[:, 0])\n",
    "        sample_Y = map(int, sample[:, 1])\n",
    "        L_X.extend(sample_X)\n",
    "        L_Y.extend(sample_Y)\n",
    "    \n",
    "    for k in range(n_outliers):\n",
    "        (x, y) = (np.random.randint(image[0]), np.random.randint(image[1]))\n",
    "        L_X.append(x)\n",
    "        L_Y.append(y)\n",
    "    \n",
    "    return (L_X, L_Y)\n",
    "\n",
    "def plot_data(D, ax):\n",
    "    L_x, L_y = D\n",
    "    ax.plot(L_x, L_y, '.')\n",
    "\n",
    "def plot_line(line, image, ax):\n",
    "    a, b = line\n",
    "    X = []\n",
    "    Y = []\n",
    "    for x in range(image[0]):\n",
    "        y = a*x+b\n",
    "        if y >= 0 and y < image[1]:\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "    ax.plot(X, Y)\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(0, image_size[0])\n",
    "ax.set_ylim(0, image_size[1])\n",
    "line = generate_line(image_size)\n",
    "print(line)\n",
    "D = generate_data(line, image_size, sigma_noise)\n",
    "plot_data(D, ax)\n",
    "plot_line(line, image_size, ax)\n",
    "fig.show()\n",
    "#print(D)\n",
    "print(len(D[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss between 2 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5.75, -463.5)\n",
      "(-5.43, 651.74)\n",
      "36218\n",
      "3782\n",
      "True\n",
      "area final =  3782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:459: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def point_y_in_image(l, x, image_y):\n",
    "    a, b = l\n",
    "    y = int(a*x+b)\n",
    "    y = min(max(y, 0), image_y-1)\n",
    "    return y\n",
    "\n",
    "def loss(l1, l2, image):\n",
    "    area1 = 0\n",
    "    for x in range(image[0]):\n",
    "        y1 = point_y_in_image(l1, x, image[1])\n",
    "        y2 = point_y_in_image(l2, x, image[1])\n",
    "        area1 += abs(y1-y2)\n",
    "    area2 = image[0]*image[1] - area1\n",
    "    \n",
    "    inter = intersect(l1, l2, image)\n",
    "    if inter :\n",
    "        area = min(area1, area2)\n",
    "    else:\n",
    "        sign = change_sign(l1, l2, image)\n",
    "        if l1[0]*l2[0] <=0 and sign:\n",
    "            area = area2\n",
    "        else:\n",
    "            area = area1\n",
    "    #print(\"area final = \", area)\n",
    "    return area\n",
    "\n",
    "def intersect(l1, l2, image):\n",
    "    a1, b1 = l1\n",
    "    a2, b2 = l2\n",
    "    if a1 == a2:\n",
    "        return False\n",
    "    else:\n",
    "        x = (b2 - b1)/(a1-a2)\n",
    "        y = a1*x+b1\n",
    "        if x >= 0 and x < image[0] and y >= 0 and y < image[1]:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "def change_sign(l1, l2, image):\n",
    "    a1, b1 = l1\n",
    "    a2, b2 = l2\n",
    "    d1 = b1 - b2\n",
    "    x = image[0]\n",
    "    d2 = (a1*x+b1)-(a2*x+b2)\n",
    "    if d1*d2 < 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def plot_loss(l1, l2, image, ax):\n",
    "    plot_line(l1, image_size, ax)\n",
    "    plot_line(l2, image_size, ax)\n",
    "    area_X = []\n",
    "    area_Y = []\n",
    "    area1 = 0\n",
    "    for x in range(image[0]):\n",
    "        y1 = point_y_in_image(l1, x, image[1])\n",
    "        y2 = point_y_in_image(l2, x, image[1])\n",
    "        area1 += abs(y1-y2)\n",
    "        for k in range(min(y1, y2), max(y1, y2)):\n",
    "            area_X.append(x)\n",
    "            area_Y.append(k)\n",
    "    ax.plot(area_X, area_Y, '.')\n",
    "    print(area1)\n",
    "    area2 = image[0]*image[1] - area1\n",
    "    print(area2)\n",
    "    \n",
    "    inter = intersect(l1, l2, image)\n",
    "    print(inter)\n",
    "    if inter :\n",
    "        area = min(area1, area2)\n",
    "    else:\n",
    "        sign = change_sign(l1, l2, image)\n",
    "        print(sign)\n",
    "        if l1[0]*l2[0] <=0 and sign:\n",
    "            area = area2\n",
    "        else:\n",
    "            area = area1\n",
    "    print(\"area final = \", area)\n",
    "    fig.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(0, image_size[0])\n",
    "ax.set_ylim(0, image_size[1])\n",
    "line1 = generate_line(image_size)\n",
    "print(line1)\n",
    "\n",
    "line2 = generate_line(image_size)\n",
    "print(line2)\n",
    "plot_loss(line1, line2, image_size, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network():\n",
    "\n",
    "    def __init__(self, input_shape, batch_size=32, epochs=5):\n",
    "        \n",
    "        self.model_cnn = Sequential()\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs=epochs\n",
    "\n",
    "        self.model_cnn.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "        self.model_cnn.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "        self.model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        self.model_cnn.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "        self.model_cnn.add(Dropout(0,25))\n",
    "        self.model_cnn.add(Flatten())\n",
    "        self.model_cnn.add(Dense(128, activation='relu'))\n",
    "        self.model_cnn.add(Dropout(0.5))\n",
    "        self.model_cnn.add(Dense(1, activation='relu'))\n",
    "\n",
    "        self.model_cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                          optimizer=keras.optimizers.Adadelta(),\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "        self.model_cnn.summary()\n",
    "        \n",
    "        \n",
    "    def train_nn(self, x_train, y_train, x_test, y_test):\n",
    "        # Run the train\n",
    "        history = self.model_cnn.fit(x_train, y_train,\n",
    "                                batch_size=self.batch_size,\n",
    "                                epochs=self.epochs,\n",
    "                                verbose=1,\n",
    "                                validation_data=(x_test, y_test))\n",
    "        \n",
    "        score = self.model_cnn.evaluate(x_test, y_test, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "    def predict(x):\n",
    "        y = self.model_cnn.predict_classes(x)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(data, i1, i2):\n",
    "    p2 = (data[0][i2], data[1][i2])\n",
    "    p1 = (data[0][i1], data[1][i1])\n",
    "    vec = (p2[0]-p1[0], p2[1]-p1[0])\n",
    "    feature = (p1, p2, vec)\n",
    "    return feature\n",
    "    \n",
    "\n",
    "def generate_training_data(image, sigma, nbr, nbr_per_line):\n",
    "    Lines = []\n",
    "    Datas = []\n",
    "    X = []\n",
    "    Y = []\n",
    "    for k in range(nbr):\n",
    "        line_ref = generate_line(image)\n",
    "        Lines.append(line_ref)\n",
    "        data = generate_data(line_ref, image, sigma)\n",
    "        Datas.append(data)\n",
    "        nbr_points = len(data[0])\n",
    "        for i in range(int(sqrt(nbr_per_line))):\n",
    "            i1 = np.random.randint(nbr_points)\n",
    "            for i in range(int(sqrt(nbr_per_line))):\n",
    "                i2 = np.random.randint(nbr_points)\n",
    "                while i2 == i1:\n",
    "                    i2 = np.random.randint(nbr_points)\n",
    "                feature=compute_features(data, i1, i2)\n",
    "                X.append(feature)\n",
    "                p2 = (data[0][i2], data[1][i2])\n",
    "                p1 = (data[0][i1], data[1][i1])\n",
    "                line = compute_line_from_points(p1, p2)\n",
    "                area = loss(line_ref, line, image)\n",
    "                Y.append(area)\n",
    "    return (X, Y)\n",
    "\n",
    "def split_training(xy, prop=0.1):\n",
    "    (X, Y) = xy\n",
    "    k = int(prop*len(X))\n",
    "    x_test = X[:k]\n",
    "    y_test = Y[:k]\n",
    "    x_train = X[k:]\n",
    "    y_train = Y[k:]\n",
    "    return ((x_test, y_test), (x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(image, sigma, nbr, nbr_per_line, batch_size=32, epochs=5):\n",
    "    ((x_test, y_test), (x_train, y_train)) = split_training(generate_training_data(image, sigma, nbr, nbr_per_line))\n",
    "    input_shape = (2, 2, 2)\n",
    "    model = Network(input_shape, batch_size=batch_size, epochs=epochs)\n",
    "    print(\"training...\", end='')\n",
    "    model.train_nn(x_train, y_train, x_test, y_test)\n",
    "    print(\"done\")\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute weights from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights(model, data, i1):\n",
    "    weights = []\n",
    "    n = len(data[0])\n",
    "    \n",
    "    print(data)\n",
    "    p1 = data[0][i1], data[1][i1]\n",
    "    for i2 in range(n):\n",
    "        if i2==i1:\n",
    "            weights.append(0)\n",
    "        else:\n",
    "            features = compute_features(data, i1, i2)\n",
    "            p2 = data[0][i2], data[1][i2]\n",
    "            w = model.predict(features)\n",
    "            weights.append(w)\n",
    "    return weights\n",
    "\n",
    "def sample_from_weights(data, weights, sample, sigma=5):\n",
    "    n = len(data[0])\n",
    "    m = 1\n",
    "    if len(sample) == 0:\n",
    "        x1 = np.random.randint(n)\n",
    "        for k in range(1000):\n",
    "            x2 = int(np.random.normal(loc=x2, scale=sigma))\n",
    "            alpha = weights[x2]/weights[x1]\n",
    "            u = random.uniform(0, 1)\n",
    "            if u <= alpha:\n",
    "                x1 = x2\n",
    "    else:\n",
    "        x1 = sample[-1]\n",
    "    \n",
    "    for k in range(m):\n",
    "        x2 = int(np.random.normal(loc=x2, scale=sigma))\n",
    "        alpha = weights[x2]/weights[x1]\n",
    "        u = random.uniform(0, 1)\n",
    "        if u <= alpha:\n",
    "            x1 = x2\n",
    "        sample.append(x1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ransac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inliers(data, line, threshold):\n",
    "    a, b = line\n",
    "    X, Y = data\n",
    "    Inliers = []\n",
    "    for x in X:\n",
    "        if abs((a*x+b) - y) < threshold:\n",
    "            Inliers.append((x, y))\n",
    "    return Inliers\n",
    "\n",
    "def get_model(model, data, image, sample):\n",
    "    n = len(data[0])\n",
    "    i1 = np.random.randint(n)\n",
    "    weights = compute_weights(model, data, i1)\n",
    "    sample_from_weights(data, weights, sample)\n",
    "    i2 = sample[-1]\n",
    "    p1 = data[0][i1], data[1][i1]\n",
    "    p2 = data[0][i2], data[1][i2]\n",
    "    line = compute_line_from_points(p1, p2)\n",
    "    return line\n",
    "\n",
    "\n",
    "def update_stopping_criterion(k, inliers, proba):\n",
    "    if k > 100:\n",
    "        return true\n",
    "    return false\n",
    "\n",
    "\n",
    "def ransac(model, data, threshold, image, proba):\n",
    "    k = 0\n",
    "    inliers_max = []\n",
    "    line_max = None\n",
    "    end = False\n",
    "    while not end:\n",
    "        sample = []\n",
    "        line = get_model(model, data, image, sample)\n",
    "        inliers = get_inliers(data, line, threshold)\n",
    "        if len(inliers) > len(inliers_max):\n",
    "            inliers_max = inliers\n",
    "            line_max = line\n",
    "        k += 1\n",
    "        end = update_stopping_criterion(k, inliers, proba)\n",
    "    return line_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 3 from 2 for 'conv2d_6/convolution' (op: 'Conv2D') with input shapes: [?,2,2,2], [3,3,2,32].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1625\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1626\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1627\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 3 from 2 for 'conv2d_6/convolution' (op: 'Conv2D') with input shapes: [?,2,2,2], [3,3,2,32].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-366-cc5747663be5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mline_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-366-cc5747663be5>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(image, sigma)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mnbr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mnbr_per_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbr_per_line\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mline_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mransac\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-362-38ed5e8c138c>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(image, sigma, nbr, nbr_per_line, batch_size, epochs)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerate_training_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbr_per_line\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training...\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_nn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-355-e623327823dd>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_shape, batch_size, epochs)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_cnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_cnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_cnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    163\u001b[0m                     \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                     \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m                     \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[1;31m# Actually call the layer,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[1;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m                 dilation_rate=self.dilation_rate)\n\u001b[0m\u001b[0;32m    172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             outputs = K.conv3d(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[0;32m   3648\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3649\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3650\u001b[1;33m         data_format=tf_data_format)\n\u001b[0m\u001b[0;32m   3651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_first'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtf_data_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'NHWC'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[1;34m(input, filter, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         data_format=data_format)\n\u001b[1;32m--> 781\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 869\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         name=self.name)\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1041\u001b[0m         \u001b[1;34m\"Conv2D\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m         data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[0;32m   1044\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                 instructions)\n\u001b[1;32m--> 488\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3270\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3271\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3272\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3273\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3274\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1788\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1789\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1790\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1792\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1627\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative dimension size caused by subtracting 3 from 2 for 'conv2d_6/convolution' (op: 'Conv2D') with input shapes: [?,2,2,2], [3,3,2,32]."
     ]
    }
   ],
   "source": [
    "def test(image, sigma):\n",
    "    line = generate_line(image)\n",
    "    data = generate_data(line, image, sigma)\n",
    "    \n",
    "    nbr = 50\n",
    "    nbr_per_line = 100\n",
    "    model = train_model(image, sigma, nbr, nbr_per_line)\n",
    "    \n",
    "    line_predict = ransac(model, data, 3, image, 0.1)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0, image[0])\n",
    "    ax.set_ylim(0, image[1])\n",
    "    plot_data(data, ax)\n",
    "    plot_line(line, image, ax)\n",
    "    plot_line(line_predict, image, ax)\n",
    "    fig.show()\n",
    "    \n",
    "    return line_predict\n",
    "\n",
    "test(image_size, sigma)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
