{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "from keras import activations\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from matplotlib import pyplot as plt\n",
    "from math import *\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_noise = [2, 2]\n",
    "image_size = (200, 200)\n",
    "\n",
    "def generate_line(image):\n",
    "    a = int(random.uniform(-10, 10) * 100) / 100\n",
    "    p = (np.random.randint(image[0]), np.random.randint(image[1]))\n",
    "    b = p[1] - a*p[0]\n",
    "    return (a, b)\n",
    "\n",
    "def compute_line_from_points(p1, p2, image):\n",
    "    x1, y1 = int(image[0]*p1[0]), int(image[1]*p1[1])\n",
    "    x2, y2 = int(image[0]*p2[0]), int(image[1]*p2[1])\n",
    "    if (x2-x1) != 0:\n",
    "        a = int((y2-y1)/(x2-x1) * 100) / 100\n",
    "    else:\n",
    "        a = 100\n",
    "    b = y1 - a*x1\n",
    "    return (a, b)\n",
    "    \n",
    "\n",
    "def generate_data(line, image, sigma, n_inliers, n_outliers):\n",
    "    a, b = line\n",
    "    L_X = []\n",
    "    L_Y = []\n",
    "    Points = []\n",
    "    for x in range(image[0]):\n",
    "        y = a*x+b\n",
    "        if y >= 0 and y < image[1]:\n",
    "            p = np.array([x, y])\n",
    "            Points.append(p)\n",
    "    covariance = np.diag(np.array(sigma) ** 2)\n",
    "    n_i = max(1, n_inliers // len(Points))\n",
    "    for point in Points:\n",
    "        sample = np.random.multivariate_normal(point, covariance, n_i)\n",
    "        sample_X = map(lambda x: int(x)/image[0], sample[:, 0])\n",
    "        sample_Y = map(lambda x: int(x)/image[1], sample[:, 1])\n",
    "        L_X.extend(sample_X)\n",
    "        L_Y.extend(sample_Y)\n",
    "    \n",
    "    for k in range(n_outliers):\n",
    "        (x, y) = (np.random.randint(image[0])/image[0], np.random.randint(image[1])/image[1])\n",
    "        L_X.append(x)\n",
    "        L_Y.append(y)\n",
    "    \n",
    "    return (L_X, L_Y)\n",
    "\n",
    "def plot_data(D, ax, c=None):\n",
    "    L_x, L_y = D\n",
    "    ax.plot(L_x, L_y, '.', c=c)\n",
    "\n",
    "def plot_line(line, image, ax, c=None):\n",
    "    a, b = line\n",
    "    X = []\n",
    "    Y = []\n",
    "    for x in range(image[0]):\n",
    "        y = a*x+b\n",
    "        if y >= 0 and y < image[1]:\n",
    "            X.append(x/image[0])\n",
    "            Y.append(y/image[1])\n",
    "    ax.plot(X, Y, c=c)\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "line = generate_line(image_size)\n",
    "print(line)\n",
    "D = generate_data(line, image_size, sigma_noise, 100, 10)\n",
    "plot_data(D, ax)\n",
    "plot_line(line, image_size, ax)\n",
    "fig.show()\n",
    "#print(D)\n",
    "print(len(D[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss between 2 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_y_in_image(l, x, image_y):\n",
    "    a, b = l\n",
    "    y = int(a*x+b)\n",
    "    y = min(max(y, 0), image_y-1)\n",
    "    return y\n",
    "\n",
    "def intersect(l1, l2, image):\n",
    "    a1, b1 = l1\n",
    "    a2, b2 = l2\n",
    "    if a1 == a2:\n",
    "        return False\n",
    "    else:\n",
    "        x = (b2 - b1)/(a1-a2)\n",
    "        y = a1*x+b1\n",
    "        if x >= 0 and x < image[0] and y >= 0 and y < image[1]:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "def change_sign(l1, l2, image):\n",
    "    a1, b1 = l1\n",
    "    a2, b2 = l2\n",
    "    d1 = b1 - b2\n",
    "    x = image[0]\n",
    "    d2 = (a1*x+b1)-(a2*x+b2)\n",
    "    if d1*d2 < 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def loss_weights(l1, l2, image):\n",
    "    area1 = 0\n",
    "    for x in range(image[0]):\n",
    "        y1 = point_y_in_image(l1, x, image[1])\n",
    "        y2 = point_y_in_image(l2, x, image[1])\n",
    "        area1 += abs(y1-y2)\n",
    "    area2 = image[0]*image[1] - area1\n",
    "    \n",
    "    inter = intersect(l1, l2, image)\n",
    "    if inter :\n",
    "        area = min(area1, area2)\n",
    "    else:\n",
    "        sign = change_sign(l1, l2, image)\n",
    "        if l1[0]*l2[0] <=0 and sign:\n",
    "            area = area2\n",
    "        else:\n",
    "            area = area1\n",
    "    #print(\"area final = \", area)\n",
    "    area = 1 - (area/(image[0]*image[1]))\n",
    "    return area\n",
    "\n",
    "def plot_loss(l1, l2, image, ax):\n",
    "    plot_line(l1, image_size, ax)\n",
    "    plot_line(l2, image_size, ax)\n",
    "    area_X = []\n",
    "    area_Y = []\n",
    "    area1 = 0\n",
    "    for x in range(image[0]):\n",
    "        y1 = point_y_in_image(l1, x, image[1])\n",
    "        y2 = point_y_in_image(l2, x, image[1])\n",
    "        area1 += abs(y1-y2)\n",
    "        for k in range(min(y1, y2), max(y1, y2)):\n",
    "            area_X.append(x/image[0])\n",
    "            area_Y.append(k/image[1])\n",
    "    ax.plot(area_X, area_Y, '.')\n",
    "    print(area1)\n",
    "    area2 = image[0]*image[1] - area1\n",
    "    print(area2)\n",
    "    \n",
    "    inter = intersect(l1, l2, image)\n",
    "    print(inter)\n",
    "    if inter :\n",
    "        area = min(area1, area2)\n",
    "    else:\n",
    "        sign = change_sign(l1, l2, image)\n",
    "        print(sign)\n",
    "        if l1[0]*l2[0] <=0 and sign:\n",
    "            area = area2\n",
    "        else:\n",
    "            area = area1\n",
    "\n",
    "    area = 1 - (area/(image[0]*image[1])) \n",
    "    print(\"area final = \", area)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "line1 = generate_line(image_size)\n",
    "print(line1)\n",
    "\n",
    "line2 = generate_line(image_size)\n",
    "print(line2)\n",
    "plot_loss(line1, line2, image_size, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_to_line(p, l, image):\n",
    "    a, b = l\n",
    "    x, y = p\n",
    "    xb, yb = x*image[0], y*image[0]\n",
    "    d = ((a*xb+b) - yb)/sqrt(1+a*a)\n",
    "    return d\n",
    "\n",
    "def dist_points_to_line(data, line, image, n_inliers):\n",
    "    X, Y = data[0][:n_inliers], data[1][:n_inliers]\n",
    "    dist = 0\n",
    "    for i in range(len(X)):\n",
    "        p = X[i], Y[i]\n",
    "        dp = dist_to_line(p, line, image)\n",
    "        dist += dp**2\n",
    "    return dist\n",
    "\n",
    "def loss_dist_points(data, line, dist_ref, image, n_inliers):\n",
    "    dist = dist_points_to_line(data, line, image, n_inliers)\n",
    "    return dist_ref/dist\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformationNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(TransformationNet, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.conv_1 = nn.Conv1d(input_dim, 64, 1)\n",
    "        self.conv_2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv_3 = nn.Conv1d(128, 1024, 1)\n",
    "\n",
    "        self.bn_1 = nn.BatchNorm1d(64)\n",
    "        self.bn_2 = nn.BatchNorm1d(128)\n",
    "        self.bn_3 = nn.BatchNorm1d(1024)\n",
    "        self.bn_4 = nn.BatchNorm1d(512)\n",
    "        self.bn_5 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.fc_1 = nn.Linear(1024, 512)\n",
    "        self.fc_2 = nn.Linear(512, 256)\n",
    "        self.fc_3 = nn.Linear(256, self.output_dim*self.output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        num_points = x.shape[1]\n",
    "\n",
    "        x = x.transpose(2, 1)\n",
    "        x = F.relu(self.bn_1(self.conv_1(x)))\n",
    "        x = F.relu(self.bn_2(self.conv_2(x)))\n",
    "        x = F.relu(self.bn_3(self.conv_3(x)))\n",
    "\n",
    "        x = nn.MaxPool1d(num_points)(x)\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn_4(self.fc_1(x)))\n",
    "        x = F.relu(self.bn_5(self.fc_2(x)))\n",
    "        x = self.fc_3(x)\n",
    "\n",
    "        identity_matrix = torch.eye(self.output_dim)\n",
    "        if torch.cuda.is_available():\n",
    "            identity_matrix = identity_matrix.cuda()\n",
    "        x = x.view(-1, self.output_dim, self.output_dim) + identity_matrix\n",
    "        return x\n",
    "\n",
    "class BasePointNet(nn.Module):\n",
    "\n",
    "    def __init__(self, point_dimension, return_local_features=False):\n",
    "        super(BasePointNet, self).__init__()\n",
    "        self.return_local_features = return_local_features\n",
    "        self.input_transform = TransformationNet(input_dim=point_dimension, output_dim=point_dimension)\n",
    "        self.feature_transform = TransformationNet(input_dim=64, output_dim=64)\n",
    "\n",
    "        self.conv_1 = nn.Conv1d(point_dimension, 64, 1)\n",
    "        self.conv_2 = nn.Conv1d(64, 64, 1)\n",
    "        self.conv_3 = nn.Conv1d(64, 64, 1)\n",
    "        self.conv_4 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv_5 = nn.Conv1d(128, 1024, 1)\n",
    "\n",
    "        self.bn_1 = nn.BatchNorm1d(64)\n",
    "        self.bn_2 = nn.BatchNorm1d(64)\n",
    "        self.bn_3 = nn.BatchNorm1d(64)\n",
    "        self.bn_4 = nn.BatchNorm1d(128)\n",
    "        self.bn_5 = nn.BatchNorm1d(1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "        num_points = x.shape[1]\n",
    "\n",
    "        input_transform = self.input_transform(x)\n",
    "\n",
    "        x = torch.bmm(x, input_transform)\n",
    "        x = x.transpose(2, 1)\n",
    "        x = F.relu(self.bn_1(self.conv_1(x)))\n",
    "        x = F.relu(self.bn_2(self.conv_2(x)))\n",
    "        x = x.transpose(2, 1)\n",
    "\n",
    "        feature_transform = self.feature_transform(x)\n",
    "\n",
    "        x = torch.bmm(x, feature_transform)\n",
    "        local_point_features = x\n",
    "\n",
    "        x = x.transpose(2, 1)\n",
    "        x = F.relu(self.bn_3(self.conv_3(x)))\n",
    "        x = F.relu(self.bn_4(self.conv_4(x)))\n",
    "        x = F.relu(self.bn_5(self.conv_5(x)))\n",
    "        x = nn.MaxPool1d(num_points)(x)\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        if self.return_local_features:\n",
    "            x = x.view(-1, 1024, 1).repeat(1, 1, num_points)\n",
    "            return torch.cat([x.transpose(2, 1), local_point_features], 2), feature_transform\n",
    "        else:\n",
    "            return x, feature_transform\n",
    "\n",
    "class FeaturesPointNet(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout, point_dimension):\n",
    "        super(FeaturesPointNet, self).__init__()\n",
    "        self.base_pointnet = BasePointNet(return_local_features=False, point_dimension=point_dimension)\n",
    "\n",
    "        self.fc_1 = nn.Linear(1024, 512)\n",
    "        self.fc_2 = nn.Linear(512, 256)\n",
    "        #self.fc_3 = nn.Linear(256, num_classes)\n",
    "\n",
    "        self.bn_1 = nn.BatchNorm1d(512)\n",
    "        self.bn_2 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, feature_transform = self.base_pointnet(x)\n",
    "\n",
    "        x = F.relu(self.bn_1(self.fc_1(x)))\n",
    "        x = F.relu(self.bn_2(self.fc_2(x)))\n",
    "        x = self.dropout_1(x)\n",
    "\n",
    "        #return F.log_softmax(self.fc_3(x), dim=1), feature_transform\n",
    "        return x, feature_transform\n",
    "\n",
    "\n",
    "class Weights(nn.Module):\n",
    "\n",
    "    \n",
    "    def __init__(self, dropout=0.3, point_dimension=2):\n",
    "        super(Weights, self).__init__()\n",
    "        self.point1 = FeaturesPointNet(dropout, point_dimension)\n",
    "        self.point2 = FeaturesPointNet(dropout, point_dimension)\n",
    "\n",
    "        self.fc_1 = nn.Linear(518, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        n = (x.shape[1] - 3)//2\n",
    "        x1 = x[:, :n]\n",
    "        x2 = x[:, n:2*n]\n",
    "        v = x[:, 2*n]\n",
    "        p1 = x[:, 2*n+1]\n",
    "        p2 = x[:, 2*n+2]\n",
    "        #print(\"x1.shape= \", x1.shape)\n",
    "        #print(\"x2.shape= \", x2.shape)\n",
    "        #print(\"v.shape = \", v.shape)\n",
    "        \n",
    "        assert 2*n+2==x.shape[1]-1\n",
    "        \n",
    "        x1, feature_transform1 = self.point1(x1)\n",
    "        x2, feature_transform2 = self.point2(x2)\n",
    "        #print(\"feature1.shape = \", x1.shape)\n",
    "        #print(\"feature2.shape = \", x2.shape)\n",
    "        #print(feature_transform1.shape)\n",
    "        \n",
    "        x_tot = torch.cat((x1, x2), dim=1)\n",
    "        #print(\"x_tot.shape = \", x_tot.shape)\n",
    "\n",
    "        x = torch.cat((x_tot, v), dim=1)\n",
    "        x = torch.cat((x, p1), dim=1)\n",
    "        x = torch.cat((x, p2), dim=1)\n",
    "\n",
    "        #print(\"x.shape = \", x.shape)\n",
    "        #print(\"x = \", x)\n",
    "        \n",
    "        x = F.relu(self.fc_1(x))\n",
    "\n",
    "        return x #, feature_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(p1, p2):\n",
    "    (x1, y1) = p1\n",
    "    (x2, y2) = p2\n",
    "    return sqrt((x1-x2)**2+(y1-y2)**2)\n",
    "\n",
    "def reorder(L, M):\n",
    "    p = L[-1]\n",
    "    d = M[-1]\n",
    "    k = len(L) - 2\n",
    "    while k >= 0 and M[k] > d:\n",
    "        L[k+1] = L[k]\n",
    "        M[k+1] = M[k]\n",
    "        k -= 1\n",
    "    L[k+1] = p\n",
    "    M[k+1] = d\n",
    "\n",
    "def nearest_neighbors(data, i, k):\n",
    "    p = (data[0][i], data[1][i])\n",
    "    L = []\n",
    "    M = []\n",
    "    n = len(data[0])\n",
    "    for j in range(n):\n",
    "        (x, y) = (data[0][j], data[1][j])\n",
    "        d = dist((x, y), p)\n",
    "        if len(L) < k:\n",
    "            L.append((x, y))\n",
    "            M.append(d)\n",
    "            reorder(L, M)\n",
    "        else:\n",
    "            d2 = M[-1]\n",
    "            if d < d2:\n",
    "                L[-1] = (x, y)\n",
    "                M[-1] = d\n",
    "                reorder(L, M)\n",
    "    return L\n",
    "\n",
    "def get_neihborhood_patch(data, k, image, size, scale=(1, 1)):\n",
    "    scale_x, scale_y = scale\n",
    "    size_x, size_y = size\n",
    "    n = len(data[0])\n",
    "    (x, y) = data[0][k]*image[0], data[1][k]*image[1]\n",
    "    L = [[0]*(2*size_x+1) for _ in range(2*size_y+1)]\n",
    "    for i in range(n):\n",
    "        (xb, yb) = data[0][i]*image[0], data[1][i]*image[1]\n",
    "        dx = xb-x\n",
    "        if abs(dx) < scale_x/2.:\n",
    "            lx = 0\n",
    "        elif dx >=0.5:\n",
    "            dx = dx - scale_x/2.\n",
    "            lx = floor(dx/scale_x)+1\n",
    "        elif dx <= -0.5:\n",
    "            dx = dx + scale_x/2.\n",
    "            lx = floor(dx/scale_x)\n",
    "        lx += size_x\n",
    "        \n",
    "        dy = yb-y\n",
    "        if abs(dy) < scale_y/2.:\n",
    "            ly = 0\n",
    "        elif dy >=0.5:\n",
    "            dy = dy - scale_y/2.\n",
    "            ly = floor(dy/scale_y)+1\n",
    "        elif dy <= -0.5:\n",
    "            dy = dy + scale_y/2.\n",
    "            ly = floor(dy/scale_y)\n",
    "        ly += size_y\n",
    "        \n",
    "        \n",
    "        if lx >= 0 and lx < 2*size_x+1 and ly >= 0 and ly < 2*size_y+1:\n",
    "            L[2*size_y - ly][lx] += 1\n",
    "    \n",
    "    return L\n",
    "\n",
    "line = generate_line(image_size)\n",
    "data = generate_data(line, image_size, sigma_noise, 200, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.xaxis.set_ticks(np.arange(0, 1, (2./image_size[0])))\n",
    "ax.yaxis.set_ticks(np.arange(0, 1, (2./image_size[1])))\n",
    "plot_data(data, ax)\n",
    "plot_line(line, image_size, ax)\n",
    "k = np.random.randint(len(data[0]))\n",
    "L = get_neihborhood_patch(data, k, image_size, (2, 2), scale=(2, 2))\n",
    "print(L)\n",
    "circle_1 = plt.Circle((data[0][k], data[1][k]), 2./image_size[0], color='r')\n",
    "print(data[0][k], data[1][k])\n",
    "ax.add_artist(circle_1)\n",
    "plt.grid()\n",
    "fig.show()\n",
    "#plt.savefig('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_points(points, p):\n",
    "    (x, y) = p\n",
    "    L = []\n",
    "    for point in points:\n",
    "        (xp, yp) = point\n",
    "        L.append([xp-x, yp-y])\n",
    "    return L\n",
    "\n",
    "def compute_features(data, i1, i2):\n",
    "    p2 = (data[0][i2], data[1][i2])\n",
    "    p1 = (data[0][i1], data[1][i1])\n",
    "    vec = [p2[0]-p1[0], p2[1]-p1[0]]\n",
    "    k = 10\n",
    "    x1 = center_points(nearest_neighbors(data, i1, k), p1)\n",
    "    x2 = center_points(nearest_neighbors(data, i2, k), p2)\n",
    "    feature = x1+x2\n",
    "    feature.append(vec)\n",
    "    feature.append([p1[0], p1[1]])\n",
    "    feature.append([p2[0], p2[1]])\n",
    "    return feature\n",
    "    \n",
    "\n",
    "def generate_training_data(image, sigma, nbr, nbr_per_line, nbr_inliers, nbr_outliers):\n",
    "    Lines = []\n",
    "    Datas = []\n",
    "    X = []\n",
    "    Y = []\n",
    "    for k in range(nbr):\n",
    "        line_ref = generate_line(image)\n",
    "        Lines.append(line_ref)\n",
    "        data = generate_data(line_ref, image, sigma, nbr_inliers, nbr_outliers)\n",
    "        n_inliers_precise = len(data[0]) - nbr_outliers\n",
    "        dist_ref = dist_points_to_line(data, line_ref, image, n_inliers_precise)\n",
    "        Datas.append(data)\n",
    "        nbr_points = len(data[0])\n",
    "        for i in range(int(sqrt(nbr_per_line))):\n",
    "            i1 = np.random.randint(nbr_points)\n",
    "            for i in range(int(sqrt(nbr_per_line))):\n",
    "                i2 = np.random.randint(nbr_points)\n",
    "                while i2 == i1:\n",
    "                    i2 = np.random.randint(nbr_points)\n",
    "                feature=compute_features(data, i1, i2)\n",
    "                X.append(feature)\n",
    "                p2 = (data[0][i2], data[1][i2])\n",
    "                p1 = (data[0][i1], data[1][i1])\n",
    "                line = compute_line_from_points(p1, p2, image)\n",
    "                #area = loss_weights(line_ref, line, image)\n",
    "                area = loss_dist_points(data, line, dist_ref, image, n_inliers_precise)\n",
    "                Y.append([area])\n",
    "    #print(type(X))\n",
    "    X_tensor = torch.Tensor(X)\n",
    "    Y_tensor = torch.Tensor(Y)\n",
    "    #print(type(X_tensor))\n",
    "    #print(X_tensor.shape)\n",
    "    return (X_tensor, Y_tensor)\n",
    "\n",
    "def split_training(xy, prop=0.1):\n",
    "    (X, Y) = xy\n",
    "    k = int(prop*len(X))\n",
    "    x_test = X[:k]\n",
    "    y_test = Y[:k]\n",
    "    x_train = X[k:]\n",
    "    y_train = Y[k:]\n",
    "    return ((x_test, y_test), (x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Weights().to(DEVICE)\n",
    "\n",
    "sigma_noise = [2, 2]\n",
    "image_size = (400, 400)\n",
    "nbr_inliers=300\n",
    "nbr_outliers=400\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(y1, y2):\n",
    "    n = len(y1[0])\n",
    "    s = 0\n",
    "    for k in range(n):\n",
    "        print(y1[k][0], y2[k][0])\n",
    "        s += abs(y1[k][0]-y2[k][0])\n",
    "    return s\n",
    "\n",
    "def train_model(model, image, sigma, nbr, nbr_per_line, epochs, batch_size, nbr_inliers, nbr_outliers):\n",
    "    ((x_test, y_test), (x_train, y_train)) = split_training(generate_training_data(image, sigma, nbr, nbr_per_line, nbr_inliers, nbr_outliers))\n",
    "    #x_test, y_test = x_test.to(DEVICE), y_test.to(DEVICE)\n",
    "    #x_train, y_train = x_train.to(DEVICE), y_train.to(DEVICE)\n",
    "    #print(x_test, y_test)\n",
    "    #print(x_train, y_train)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=10**(-2))\n",
    "    print(\"data generated\")\n",
    "    \n",
    "    # Train step\n",
    "    train_ds = TensorDataset(x_train, y_train)\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    print(len(train_dl))\n",
    "    \n",
    "    valid_ds = TensorDataset(x_test, y_test)\n",
    "    valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=True)\n",
    "    m_train = 0\n",
    "    for k in range(epochs):\n",
    "        loss_train = 0\n",
    "        for xb, yb in train_dl:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            #print(xb.shape)\n",
    "            #print(yb.shape)\n",
    "            model.train()  # <-- here\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_predict = model(xb)\n",
    "            #print(xb.shape)\n",
    "            loss = loss_fn(y_predict, yb)\n",
    "            loss_train += loss.item()\n",
    "            m_train += len(yb)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Eval\n",
    "        model.eval()  # <-- here\n",
    "        with torch.no_grad():\n",
    "            loss_eval = sum(loss_fn(model(xb.to(DEVICE)), yb.to(DEVICE)) for xb, yb in valid_dl)\n",
    "            m_test = sum(len(yb) for xb, yb in valid_dl)\n",
    "\n",
    "        print(\"iteration = \", k+1, \" ; loss_train = \", loss_train, \" ; loss_eval = \", loss_eval.item())\n",
    "        \n",
    "        if k == epochs - 1:\n",
    "            last_weight = model(x_test.to(DEVICE))\n",
    "            print(last_weight)\n",
    "            print(y_test)\n",
    "            print(sum(abs(last_weight[i][0]-y_test[i][0]) for i in range(len(y_test)))/len(y_test))\n",
    "\n",
    "train_model(model, image_size, sigma_noise, 50, 529, 60, 100, nbr_inliers, nbr_outliers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_weights(weights):\n",
    "    n = len(weights)\n",
    "    s = 0.\n",
    "    for i in range(n):\n",
    "        w = weights[i]\n",
    "        s += w\n",
    "    return s/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights(weights, coord, p1, image, ref=False):\n",
    "    #print(max(weights), min(weights))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    n = len(weights)\n",
    "\n",
    "    for i in range(n):\n",
    "        (x, y) = coord[i]\n",
    "        w = weights[i]\n",
    "        if isinstance(w, list):\n",
    "            w = w[0]\n",
    "        #r = (exp(10*w)/exp(7))\n",
    "        #if ref:*\n",
    "        #r = exp(8*w)/exp(6)/image[0]\n",
    "        r = 5*w/image[0]\n",
    "        circle = plt.Circle((x, y), r, color='r')\n",
    "        if r <= 5*10**(-4):\n",
    "            circle = plt.Circle((x, y), 1./image[0], color='b')\n",
    "\n",
    "        ax.add_artist(circle)\n",
    "    #print(p1)\n",
    "    print(\"mean =\", mean_weights(weights[:][0]))\n",
    "    circle_1 = plt.Circle(p1, 4./image[0], color='g')\n",
    "    ax.add_artist(circle_1)\n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "def test_nn(model, image, sigma, nbr_inliers, nbr_outliers):\n",
    "    line_ref = generate_line(image)\n",
    "    data = generate_data(line_ref, image, sigma, nbr_inliers, nbr_outliers)\n",
    "    n_inliers_precise = len(data[0])-nbr_outliers\n",
    "    dist_ref = dist_points_to_line(data, line_ref, image, n_inliers_precise)\n",
    "    n = len(data[0])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    plot_data(data, ax)\n",
    "    fig.show()\n",
    "    \n",
    "    \n",
    "    for it in range(10):\n",
    "        i1 = np.random.randint(n)\n",
    "        X = []\n",
    "        coord = []\n",
    "        weights_ref = []\n",
    "        p1 = (data[0][i1], data[1][i1])\n",
    "        for i2 in range(n):\n",
    "            if i2!=i1:\n",
    "                feature=compute_features(data, i1, i2)\n",
    "                X.append(feature)\n",
    "                X_tensor = torch.Tensor(X)\n",
    "                  \n",
    "                \n",
    "                p2 = (data[0][i2], data[1][i2])\n",
    "                line = compute_line_from_points(p1, p2, image)\n",
    "                #area = loss_weights(line_ref, line, image)\n",
    "                area = loss_dist_points(data, line, dist_ref, image, n_inliers_precise)\n",
    "                weights_ref.append([area])\n",
    "                \n",
    "                coord.append((data[0][i2], data[1][i2]))\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            weights = model(X_tensor)\n",
    "        \n",
    "        #plot_weights(weights, coord, p1, image)\n",
    "        plot_weights(weights_ref, coord, p1, image, ref=True)\n",
    "\n",
    "test_nn(model, image_size, sigma_noise, nbr_inliers, nbr_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute weights from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights_ref(line_ref, image, data, i1):\n",
    "    coord = []\n",
    "    weights_ref = []\n",
    "    p1 = (data[0][i1], data[1][i1])\n",
    "    n = len(data[0])\n",
    "    for i2 in range(n):\n",
    "        if i2==i1:\n",
    "            weights_ref.append(0)\n",
    "        else:\n",
    "            p2 = (data[0][i2], data[1][i2])\n",
    "            line = compute_line_from_points(p1, p2, image)\n",
    "            area = loss_weights(line_ref, line, image)\n",
    "            weights_ref.append(area)\n",
    "\n",
    "        coord.append((data[0][i2], data[1][i2]))\n",
    "    return weights_ref\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights(model, data, i1, image):\n",
    "    n = len(data[0])\n",
    "\n",
    "    p1 = data[0][i1], data[1][i1]\n",
    "    X = []\n",
    "    coord = []\n",
    "    for i2 in range(n):\n",
    "        if i2!=i1:\n",
    "            feature=compute_features(data, i1, i2)\n",
    "            X.append(feature)\n",
    "            X_tensor = torch.Tensor(X)\n",
    "\n",
    "\n",
    "            p2 = (data[0][i2], data[1][i2])\n",
    "            line = compute_line_from_points(p1, p2, image)\n",
    "\n",
    "            coord.append((data[0][i2], data[1][i2]))\n",
    "            \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        weights_predict = model(X_tensor)\n",
    "    \n",
    "    weights = []\n",
    "    k = 0\n",
    "    for i in range(n):\n",
    "        if i == i1:\n",
    "            weights.append(0)\n",
    "            k = 1\n",
    "        else:\n",
    "            weights.append(weights_predict[i-k][0])\n",
    "    \n",
    "    \n",
    "    assert len(weights) == len(data[0])\n",
    "            \n",
    "    return weights\n",
    "\n",
    "        \n",
    "\n",
    "def sample_from_weights(data, weights, sigma=5):\n",
    "    n = len(data[0])\n",
    "    x1 = np.random.randint(n)\n",
    "    if max(weights) == 0:\n",
    "        return x1\n",
    "    while weights[x1] == 0:\n",
    "        x1 = np.random.randint(n)\n",
    "    for k in range(1000):\n",
    "        x2 = int(np.random.normal(loc=x1, scale=sigma))\n",
    "        while x2 < 0 or x2 >= n:\n",
    "            x2 = int(np.random.normal(loc=x1, scale=sigma))\n",
    "        alpha = weights[x2]/weights[x1]\n",
    "        u = random.uniform(0, 1)\n",
    "        if u <= alpha:\n",
    "            x1 = x2\n",
    "\n",
    "    \n",
    "    x2 = int(np.random.normal(loc=x1, scale=sigma))\n",
    "    while x2 < 0 or x2 >= n:\n",
    "        x2 = int(np.random.normal(loc=x1, scale=sigma))\n",
    "    alpha = weights[x2]/weights[x1]\n",
    "    u = random.uniform(0, 1)\n",
    "    if u <= alpha:\n",
    "        x1 = x2\n",
    "    return x1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ransac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inliers(data, line, threshold, image):\n",
    "    a, b = line\n",
    "    X, Y = data\n",
    "    Inliers = [[], []]\n",
    "    for i in range(len(X)):\n",
    "        (x, y) = (X[i], Y[i])\n",
    "        (xb, yb) = x*image[0], y*image[1]\n",
    "        if abs((a*xb+b) - yb)/sqrt(1+a*a) < threshold:\n",
    "            Inliers[0].append(x)\n",
    "            Inliers[1].append(y)\n",
    "    return Inliers\n",
    "\n",
    "def get_model(model, data, image, line_ref=None):\n",
    "    n = len(data[0])\n",
    "    i1 = np.random.randint(n)\n",
    "    if model is not None:\n",
    "        weights = compute_weights(model, data, i1, image)\n",
    "    else:\n",
    "        weights = compute_weights_ref(line_ref, image, data, i1)\n",
    "    i2 = sample_from_weights(data, weights)\n",
    "    p1 = data[0][i1], data[1][i1]\n",
    "    p2 = data[0][i2], data[1][i2]\n",
    "    line = compute_line_from_points(p1, p2, image)\n",
    "    return line #, weights, i1\n",
    "\n",
    "\n",
    "def update_stopping_criterion(k, inliers, proba):\n",
    "    if k >= 150:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def ransac(data, threshold, image, proba, line_ref=None, model=None, compare=False):\n",
    "    k = 0\n",
    "    inliers_max = [[], []]\n",
    "    line_max = None\n",
    "    end = False\n",
    "    nbr_inliers = []\n",
    "    while not end:\n",
    "        line = get_model(model, data, image, line_ref)\n",
    "        inliers = get_inliers(data, line, threshold, image)\n",
    "        if len(inliers[0]) > len(inliers_max[0]):\n",
    "            inliers_max = inliers\n",
    "            line_max = line\n",
    "        nbr_inliers.append(len(inliers_max[0]))\n",
    "\n",
    "        k += 1\n",
    "        end = update_stopping_criterion(k, inliers, proba)\n",
    "        \n",
    "        #print(\"------------------------------------\")\n",
    "        #print(\"nbr inliers = \", len(inliers[0]))\n",
    "        #print(\"line = \", line)\n",
    "        #print(\"max inliers so far = \", len(inliers_max[0]))\n",
    "    if compare:\n",
    "        return line_max, inliers_max, nbr_inliers\n",
    "    return line_max, inliers_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image_size\n",
    "sigma = sigma_noise\n",
    "n_inliers=150\n",
    "n_outliers=50\n",
    "proba = 0.1\n",
    "\n",
    "line = generate_line(image)\n",
    "data = generate_data(line, image, sigma, n_inliers, n_outliers)\n",
    "    \n",
    "threshold = 12\n",
    "    \n",
    "k = 0\n",
    "inliers_max = [[], []]\n",
    "line_max = None\n",
    "end = False\n",
    "line_ref = line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = []\n",
    "line2, weights, i1 = get_model(model, data, image, sample, line_ref)\n",
    "p1 = (data[0][i1], data[1][i1])\n",
    "inliers = get_inliers(data, line2, threshold, image)\n",
    "if len(inliers[0]) > len(inliers_max[0]):\n",
    "    inliers_max = inliers\n",
    "    line_max = line2\n",
    "k += 1\n",
    "end = update_stopping_criterion(k, inliers, proba)\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "print(\"nbr inliers = \", len(inliers[0]))\n",
    "print(\"line = \", line2)\n",
    "print(\"max inliers so far = \", len(inliers_max[0]))\n",
    "print(\"end = \", end)\n",
    "print(\"sample = \", sample)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "plot_data(data, ax, c='b')\n",
    "ax.plot([p1[0]], [p1[1]], c='g')\n",
    "plot_data(inliers, ax, c='r')\n",
    "plot_line(line2, image, ax, c='g')\n",
    "fig.show()\n",
    "\n",
    "coord = [(data[0][i], data[1][i]) for i in range(len(data[0]))]\n",
    "plot_weights(weights, coord, p1, image, ref=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_weights_ref(image, sigma, n_inliers=150, n_outliers=50):\n",
    "    line = generate_line(image)\n",
    "    data = generate_data(line, image, sigma, n_inliers, n_outliers)\n",
    "    \n",
    "    threshold = 5\n",
    "    proba = 0.1\n",
    "    \n",
    "    line_predict, inliers = ransac(data, threshold, image, proba, line_ref=line)\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    plot_data(data, ax, c='b')\n",
    "    plot_data(inliers, ax, c='r')\n",
    "    #plot_line(line, image, ax, c='g')\n",
    "    plot_line(line_predict, image, ax, c='b')\n",
    "    fig.show()\n",
    "    \n",
    "    print(\"prediction = \", line_predict)\n",
    "    print(\"ref = \", line)\n",
    "    \n",
    "    return line_predict\n",
    "\n",
    "test_weights_ref(image_size, sigma_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with and without weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_uniform(data, image):\n",
    "    n = len(data[0])\n",
    "    i1 = np.random.randint(n)\n",
    "    i2 = np.random.randint(n)\n",
    "    while i1 == i2:\n",
    "        i2 = np.random.randint(n)\n",
    "    p1 = data[0][i1], data[1][i1]\n",
    "    p2 = data[0][i2], data[1][i2]\n",
    "    line = compute_line_from_points(p1, p2, image)\n",
    "    return line\n",
    "\n",
    "\n",
    "def ransac_uniform(data, threshold, image, proba):\n",
    "    k = 0\n",
    "    inliers_max = [[], []]\n",
    "    line_max = None\n",
    "    end = False\n",
    "    nbr_inliers = []\n",
    "    while not end:\n",
    "        line = get_model_uniform(data, image)\n",
    "        inliers = get_inliers(data, line, threshold, image)\n",
    "        if len(inliers[0]) > len(inliers_max[0]):\n",
    "            inliers_max = inliers\n",
    "            line_max = line\n",
    "        nbr_inliers.append(len(inliers_max[0]))\n",
    "\n",
    "        k += 1\n",
    "        end = update_stopping_criterion(k, inliers, proba)\n",
    "        \n",
    "        #print(\"------------------------------------\")\n",
    "        #print(\"nbr inliers = \", len(inliers[0]))\n",
    "        #print(\"line = \", line)\n",
    "        #print(\"max inliers so far = \", len(inliers_max[0]))\n",
    "    return line_max, inliers_max, nbr_inliers\n",
    "\n",
    "def ransac_weights_ref(data, threshold, image, proba, line_ref):\n",
    "    k = 0\n",
    "    inliers_max = [[], []]\n",
    "    line_max = None\n",
    "    end = False\n",
    "    nbr_inliers = []\n",
    "    while not end:\n",
    "        line = get_model(None, data, image, line_ref)\n",
    "        inliers = get_inliers(data, line, threshold, image)\n",
    "        if len(inliers[0]) > len(inliers_max[0]):\n",
    "            inliers_max = inliers\n",
    "            line_max = line\n",
    "        nbr_inliers.append(len(inliers_max[0]))\n",
    "\n",
    "        k += 1\n",
    "        end = update_stopping_criterion(k, inliers, proba)\n",
    "        \n",
    "        #print(\"------------------------------------\")\n",
    "        #print(\"nbr inliers = \", len(inliers[0]))\n",
    "        #print(\"line = \", line)\n",
    "        #print(\"max inliers so far = \", len(inliers_max[0]))\n",
    "    return line_max, inliers_max, nbr_inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lines(data, line1, line2, image):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    plot_data(data, ax, c='b')\n",
    "    plot_line(line1, image, ax, c='g')\n",
    "    #plot_line(line2, image, ax, c='r')\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def compare_uniform(image, sigma, n_inliers, n_outliers, model=None,average=5):\n",
    "    Lines = []\n",
    "    Datas = []\n",
    "    for k in range(average):\n",
    "        line = generate_line(image)\n",
    "        data = generate_data(line, image, sigma, n_inliers, n_outliers)\n",
    "        Lines.append(line)\n",
    "        Datas.append(data)\n",
    "    \n",
    "    threshold = 5\n",
    "    proba = 0.1\n",
    "    \n",
    "    it = 150\n",
    "    nbr_inliers_sample = [0]*it\n",
    "    nbr_inliers_uniform = [0]*it\n",
    "    \n",
    "    for k in range(average):\n",
    "        print(k)\n",
    "        line_predict1, inliers1, nbr_inliers1 = ransac(Datas[k], threshold, image, proba, line_ref=Lines[k], model=model, compare=True)\n",
    "        line_predict2, inliers2, nbr_inliers2 = ransac_uniform(Datas[k], threshold, image, proba)\n",
    "        plot_lines(Datas[k], line_predict1, line_predict2, image)\n",
    "        \n",
    "        for j in range(it):\n",
    "            nbr_inliers_sample[j] += nbr_inliers1[j]\n",
    "            nbr_inliers_uniform[j] += nbr_inliers2[j]\n",
    "    \n",
    "    for j in range(it):\n",
    "        nbr_inliers_sample[j] /=average\n",
    "        nbr_inliers_uniform[j] /= average\n",
    "        \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(nbr_inliers_sample, c='g')\n",
    "    ax.plot(nbr_inliers_uniform, c='r')\n",
    "    fig.show()\n",
    "    \n",
    "    print(\"done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_size = [400, 400]\n",
    "#n_inliers = 300\n",
    "#n_outliers = 400\n",
    "\n",
    "compare_uniform(image_size, sigma_noise, n_inliers=nbr_inliers, n_outliers=nbr_outliers, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose first point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_density(data, image, k, n_x, n_y):\n",
    "    p = (data[0][k]*image[0], data[1][k]*image[1])\n",
    "    d_x = image[0]*n_x\n",
    "    d_y = image[1]*n_y\n",
    "    min_x = max(p[0]-d_x, 0)\n",
    "    max_x = min(p[0]+d_x, image[0])\n",
    "    min_y = max(p[1]-d_y, 0)\n",
    "    max_y = min(p[1]+d_y, image[1])\n",
    "    counter = 0\n",
    "    n = len(data[0])\n",
    "    for i in range(n):\n",
    "        (x, y) = (data[0][i]*image[0], data[1][i]*image[1])\n",
    "        if x >= min_x and x <= max_x and y >= min_y and y <= max_y:\n",
    "            counter += 1\n",
    "    return counter/((max_x-min_x)*(max_y-min_y))\n",
    "\n",
    "\n",
    "def get_density_vector(data, image, n_x, n_y):\n",
    "    n = len(data[0])\n",
    "    densities = []\n",
    "    for k in range(n):\n",
    "        w = get_density(data, image, k, n_x, n_y)\n",
    "        densities.append(w)\n",
    "    return densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model2(model, data, image, densities):\n",
    "    n = len(data[0])\n",
    "    i1 = sample_from_weights(data, densities)\n",
    "    weights = compute_weights(model, data, i1, image)\n",
    "    i2 = sample_from_weights(data, weights)\n",
    "    p1 = data[0][i1], data[1][i1]\n",
    "    p2 = data[0][i2], data[1][i2]\n",
    "    line = compute_line_from_points(p1, p2, image)\n",
    "    return line\n",
    "\n",
    "\n",
    "def ransac2(data, threshold, image, proba, model, n_x, n_y, compare=False):\n",
    "    k = 0\n",
    "    inliers_max = [[], []]\n",
    "    line_max = None\n",
    "    end = False\n",
    "    nbr_inliers = []\n",
    "    densities = get_density_vector(data, image, n_x, n_y)\n",
    "    while not end:\n",
    "        line = get_model2(model, data, image, densities)\n",
    "        inliers = get_inliers(data, line, threshold, image)\n",
    "        if len(inliers[0]) > len(inliers_max[0]):\n",
    "            inliers_max = inliers\n",
    "            line_max = line\n",
    "        nbr_inliers.append(len(inliers_max[0]))\n",
    "\n",
    "        k += 1\n",
    "        end = update_stopping_criterion(k, inliers, proba)\n",
    "        \n",
    "        #print(\"------------------------------------\")\n",
    "        #print(\"nbr inliers = \", len(inliers[0]))\n",
    "        #print(\"line = \", line)\n",
    "        #print(\"max inliers so far = \", len(inliers_max[0]))\n",
    "    if compare:\n",
    "        return line_max, inliers_max, nbr_inliers\n",
    "    return line_max, inliers_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model3(model, data, image, densities, last_weights):\n",
    "    n = len(data[0])\n",
    "    \n",
    "    threshold = 0.9\n",
    "    if last_weights is not None and mean_weights(last_weights) >= threshold:\n",
    "        i1 = sample_from_weights(data, last_weights)\n",
    "    else:\n",
    "        i1 = sample_from_weights(data, densities)\n",
    "    i1 = np.random.randint(n)    \n",
    "    weights = compute_weights(model, data, i1, image)\n",
    "    #print(mean_weights(weights))\n",
    "    i2 = sample_from_weights(data, weights)\n",
    "    p1 = data[0][i1], data[1][i1]\n",
    "    p2 = data[0][i2], data[1][i2]\n",
    "    line = compute_line_from_points(p1, p2, image)\n",
    "    return line, weights\n",
    "\n",
    "\n",
    "def ransac3(data, threshold, image, proba, model, n_x, n_y, compare=False):\n",
    "    k = 0\n",
    "    inliers_max = [[], []]\n",
    "    line_max = None\n",
    "    end = False\n",
    "    nbr_inliers = []\n",
    "    densities = get_density_vector(data, image, n_x, n_y)\n",
    "    previous_weights = None\n",
    "    while not end:\n",
    "        line, previous_weights = get_model3(model, data, image, densities, previous_weights)\n",
    "        inliers = get_inliers(data, line, threshold, image)\n",
    "        if len(inliers[0]) > len(inliers_max[0]):\n",
    "            inliers_max = inliers\n",
    "            line_max = line\n",
    "        nbr_inliers.append(len(inliers_max[0]))\n",
    "\n",
    "        k += 1\n",
    "        end = update_stopping_criterion(k, inliers, proba)\n",
    "        \n",
    "        #print(\"------------------------------------\")\n",
    "        #print(\"nbr inliers = \", len(inliers[0]))\n",
    "        #print(\"line = \", line)\n",
    "        #print(\"max inliers so far = \", len(inliers_max[0]))\n",
    "    if compare:\n",
    "        return line_max, inliers_max, nbr_inliers\n",
    "    return line_max, inliers_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test to set threshold\n",
    "\n",
    "line = generate_line(image_size)\n",
    "data = generate_data(line, image_size, sigma_noise, nbr_inliers, nbr_outliers)\n",
    "threshold = 5\n",
    "proba = 0.1\n",
    "ransac3(data, threshold, image_size, proba, model, n_x=0.05, n_y=0.05, compare=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_all(image, sigma, model, n_inliers, n_outliers, average=5):\n",
    "    Lines = []\n",
    "    Datas = []\n",
    "    for k in range(average):\n",
    "        line = generate_line(image)\n",
    "        data = generate_data(line, image, sigma, n_inliers, n_outliers)\n",
    "        Lines.append(line)\n",
    "        Datas.append(data)\n",
    "    \n",
    "    threshold = 5\n",
    "    proba = 0.1\n",
    "    \n",
    "    it = 150\n",
    "    nbr_inliers_sample = [0]*it\n",
    "    nbr_inliers_sample2 = [0]*it\n",
    "    nbr_inliers_sample3 = [0]*it\n",
    "    nbr_inliers_uniform = [0]*it\n",
    "    nbr_inliers_ref = [0]*it\n",
    "\n",
    "    \n",
    "    for k in range(average):\n",
    "        line_predict1, inliers1, nbr_inliers1 = ransac(Datas[k], threshold, image, proba, line_ref=Lines[k], model=model, compare=True)\n",
    "        print(1)\n",
    "        line_predict2, inliers2, nbr_inliers2 = ransac2(Datas[k], threshold, image, proba, model, n_x=0.05, n_y=0.05, compare=True)\n",
    "        print(2)\n",
    "        line_predict3, inliers3, nbr_inliers3 = ransac3(Datas[k], threshold, image, proba, model, n_x=0.05, n_y=0.05, compare=True)\n",
    "        print(3)\n",
    "        line_predict4, inliers4, nbr_inliers4 = ransac_uniform(Datas[k], threshold, image, proba)\n",
    "        print(4)\n",
    "        line_predict5, inliers5, nbr_inliers5 = ransac_weights_ref(Datas[k], threshold, image, proba, line_ref=Lines[k])\n",
    "        print(5)\n",
    "\n",
    "        plot_lines(Datas[k], line_predict1, line_predict2, image)\n",
    "        \n",
    "        for j in range(it):\n",
    "            nbr_inliers_sample[j] += nbr_inliers1[j]\n",
    "            nbr_inliers_sample2[j] += nbr_inliers2[j]\n",
    "            nbr_inliers_sample3[j] += nbr_inliers3[j]\n",
    "            nbr_inliers_uniform[j] += nbr_inliers4[j]\n",
    "            nbr_inliers_ref[j] += nbr_inliers5[j]\n",
    "\n",
    "            \n",
    "    \n",
    "    for j in range(it):\n",
    "        nbr_inliers_sample[j] /=average\n",
    "        nbr_inliers_sample2[j] /=average\n",
    "        nbr_inliers_sample3[j] /=average\n",
    "        nbr_inliers_uniform[j] /= average\n",
    "        nbr_inliers_ref[j] /= average\n",
    "\n",
    "        \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(nbr_inliers_sample, c='g')\n",
    "    ax.plot(nbr_inliers_sample2, c='b')\n",
    "    ax.plot(nbr_inliers_sample3, c='r')\n",
    "    ax.plot(nbr_inliers_uniform, c='black')\n",
    "    ax.plot(nbr_inliers_ref, c='orange')\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "    print(\"done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_all(image_size, sigma_noise, model, n_inliers=nbr_inliers, n_outliers=nbr_outliers, average=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Weights().to(DEVICE)\n",
    "\n",
    "sigma_noise = [2, 2]\n",
    "image_size = (400, 400)\n",
    "nbr_inliers2=300\n",
    "nbr_outliers2=250\n",
    "\n",
    "train_model(model2, image_size, sigma_noise, 50, 529, 60, 100, nbr_inliers2, nbr_outliers2)\n",
    "\n",
    "test_nn(model2, image_size, sigma_noise, nbr_inliers2, nbr_outliers2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_all(image_size, sigma_noise, model2, n_inliers=nbr_inliers2, n_outliers=nbr_outliers2, average=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Weights().to(DEVICE)\n",
    "\n",
    "sigma_noise = [2, 2]\n",
    "image_size = (400, 400)\n",
    "nbr_inliers3=400\n",
    "nbr_outliers3=500\n",
    "\n",
    "train_model(model3, image_size, sigma_noise, 50, 625, 100, 100, nbr_inliers3, nbr_outliers3)\n",
    "\n",
    "test_nn(model3, image_size, sigma_noise, nbr_inliers3, nbr_outliers3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_all(image_size, sigma_noise, model3, n_inliers=nbr_inliers3, n_outliers=nbr_outliers3, average=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
